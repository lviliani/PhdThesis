\section{Background estimation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:Backgrounds}

\textcolor{red}{Add plots for each background process}

\subsection{Top quark background \label{sec:TTBackground}}

In this analysis the top quark background is divided into two different categories depending on the number of jets in the event. In the two categories different selections are applied, especially concerning the b-tagging requirements.

The general strategy for determining the residual top events in the signal region is to first measure the top tagging efficiencies from an orthogonal region of phase space in data. The orthogonal phase space is  defined inverting the b-veto requirement of the signal region, in such a way to have a control region enriched in top quark events.  Then, using this efficiency, the number of events with the associated uncertainty is propagated from the control region to the signal region.
The number of surviving top events in the signal region would then be:

\begin{equation}
 N^{\mathrm{signal}}_{bveto} = N^{\mathrm{control}}_{btag} \cdot \frac{1-\epsilon_{\mathrm{top}}}{\epsilon_{\mathrm{top}}}
\label{eq:top_equation}
\end{equation}

where $N^{\rm control}_{\rm btag}$ is the number of events in the 
control region and $\epsilon_{\rm top}$ is the efficiency as measured
in data.

The methods to estimate the top background contribution in the two jet categories are different and are explained below.


\subsubsection{0-jets category}
Most of the top background, composed of \ttbar and tW processes, is rejected in the 0-jet bin by the
jet veto. The top-tagging efficiency in the zero jet bin, $\epsilon_{\rm tag}^{0-jet}$, is the probability for a top event to
fail one of either the b-tagging veto or the soft muon veto, and is defined as:

\begin{equation}\label{eq:eff_top_0j}
\epsilon_{\rm tag} = \frac{N_{\rm tag}^{\rm control}}{N^{\rm control}} \quad ,
\end{equation}

where $N^{\rm control}$ is the number of events in the top control phase space defined requiring one b-tagged jet with $\pt>30$\GeV, and $N_{\rm tag}^{\rm control}$ is the subset of those events that pass either the soft muon tagging or the low-\pt b jet tagging. The purity of this control sample, as estimated from simulation, is about 97\%. The remaining 3\% background contribution is estimated from simulation and subtracted from the numerator and denominator of Eq.~\eqref{eq:eff_top_0j}. The efficiency $\epsilon_{\rm top}^{0-jet}$ can then be estimated using the following formula:

\begin{equation}\label{eq:eff_top_0j}
\epsilon_{\rm top}^{0-jet} = f_{\ttbar} \cdot \epsilon_{2b} + f_{tW} \cdot ( x \cdot \epsilon_{2b} + (1-x) \cdot \epsilon_{\rm tag} ) \quad ,
\end{equation}

\begin{equation}
\epsilon_{2b} = 1 - (1 - \epsilon_{\rm tag})^{2} \quad ,
\end{equation}
where $f_{\ttbar}$ and $f_{tW}$ are the \ttbar and tW fractions respectively, $x$ is the fraction of tW events containing 2 b jets, and $\epsilon_{2b}$ is the efficiency for a top event with 0 counted jets, i.e. two soft b jets, to pass the top veto. For the ratio of \ttbar and tW cross-sections an uncertainty of 17\% is assumed. The fraction $f_{\ttbar}$ is estimated using MC simulation of the \ttbar and tW processes at NLO accuracy.

Using this procedure a data/simulation scale factor of $0.98 \pm 0.17$ is found, and is applied to correct the MC simulation in order to match the data.



\subsubsection{Category with more than 0 jets}
The strategy for the estimation of the top background in events with at least one jet with $\pt$ greater than 30 \GeV is the following. First of all the efficiency for tagging a b jet is measured both in data and simulation and the values are used to correct the simulation for different b-tagging efficiencies in data and simulation. This evaluation is performed in a control region, called CtrlTP, containing at least two jets, using a Tag\&Probe technique. The procedure to extract these scale factors is presented in Sec.~\ref{sec:TagAndProbe}. Then a larger statistics control region, CtrlDD, is defined by requiring at least one b-tagged jet and we use the simulation, corrected for the previously computed b-tagging efficiency scale factor, to derive the factor that connects the number of events in CtrlDD to the number of events in the signal region. This second step is explained in detail in Sec.~\ref{sec:DD}. 

\subsubsection{Tag\&Probe \label{sec:TagAndProbe}}
The Tag\&Probe technique is a method to estimate the efficiency of a selection on data. In can be applied whenever one has two objects in one event, by using one of the two, the \tg{}, to identify the process of interest, and using the second, the \probe{}, to actually measure the efficiency of the selection being studied. In our case we want to measure the b-tagging efficiency, so what we need is a sample with two b-jets per event. The easiest way to construct such a sample is to select $t\bar{t}$ events.

The CrtlTP control region is defined selecting the events which pass the lepton preselection cuts listed in Sec.~\ref{subsec:EventSelection}, and have at least two jets with \pt greater than 30 \GeV.
One of the two leading jets is required to have a \jpb score higher than 0.5. From events in this control region we built \tp{} pairs as follows. For each event the two leading jets are considered. If the leading jet passes the \jpb cut of 0.5, that is considered a \tg{}, and the sub-leading jet is the \probe{}. In order to avoid any bias that could arise from the probe being always the second jet, the pair is tested also in reverse order, meaning that the sub-leading jet is tested against the \tg{} selection, and in case it passes, then the leading jet is used as \probe{} in an independent \tp{} pair. This means that from each event passing the CrtlTP cuts one can build up to two \tp{} pairs. 

If the \tg{} selection were sufficient to suppress any non top events, one could estimate the efficiency by dividing the number of \tp{} pairs in which the \probe{} passes the analysis cut \jpb$>$1.4 (\tpp) by the total number of \tp{} pairs. However this is not the case. 
In order to estimate the efficiency in the presence of background a variable that discriminates between true b-jets and other jets in a $t\bar{t}$ sample is chosen. The variable is the \pt of the \probe{} jet. For real b-jets this variable has a peak around 60 \GeV, while it does not peak for other jets. The idea is to fit simultaneously the \pt spectrum for \probe{} jets in \tpp{} and \tfp{} pairs, linking together the normalizations of the two samples as follows:
\begin{equation}
N_{TPP}=N_{s}\epsilon_{s} + N_b\epsilon_{b}
\end{equation}
\begin{equation}
N_{TFP}=N_{s}(1-\epsilon_{s}) + N_b(1-\epsilon_{b})
\end{equation}
where $N_{\rm TPP}$ is the number of \tpp{} pairs, $N_{\rm TFP}$ is the number of \tfp{} pairs, $N_{\rm s}$ is the number of \tp{} pairs in which the probe is a b-jet, $N_{\rm b}$ is the number of \tp{} pairs in which the probe is a not b-jet, $\epsilon_{\rm s}$ is the b-tagging efficiency, $\epsilon_{\rm b}$ is the probability of identifying as b-jet a non-b-jets, i.e. the mistag rate. 

A $\chi^{2}$ simultaneous fit of the \probe{} \pt spectrum for \tpp{} and \tfp{} pairs is performed, deriving the shapes for true b-jets and non-b-jets from the simulation, and extracting $N_{\rm s}$, $N_{\rm b}$, $\epsilon_{\rm s}$ and $\epsilon_{\rm b}$ from the fit.
The result of the fit on simulation is shown in Fig.~\ref{fig:mc_tp}. The relevant efficiencies are:
\begin{equation}
\epsilon_{s}^{MC}=0.7663\pm0.0072
\end{equation}
\begin{equation}
\epsilon_{b}^{MC}=0.208\pm0.015
\end{equation}
We have checked that these values are consistent with the true value for the b-tagging efficiency. The true value is computed by selecting jets that are matched within a cone of $\Delta{R}<0.5$ with a generator level b-quark, and counting the faction of those that pass the \jpb cut of 1.4. This means that the \tp{} method does not introduce biases within the simulation statistic accuracy.

\begin{figure}[b]
\centering
\includegraphics[width=0.8\textwidth]{images/mc_pt_probe.pdf}
\caption{Simultaneous fit of the \tpp{} and \tfp{} pairs in the MC.\label{fig:mc_tp}}
\end{figure}

In order to assess the robustness of the fit, 5000 toy MC samples have been generated with a statistics equivalent to the one expected in data and the same fit is performed. All the 5000 fit succeeded, and the pull distributions for $\epsilon_{\rm s}$ and $\epsilon_{\rm b}$ parameters are shown in Fig.~\ref{fig:pullstp}. The plots show the pull of the efficiencies measured in the fit, where the pull variable for each toy $i$ is defined as:

\begin{equation}
pull(\epsilon_{\rm s (b)}) = \frac{\epsilon_{\rm s (b)}^{\rm true} - \epsilon_{\rm s (b)}^{i}}{\sigma(\epsilon_{\rm s (b)}^{i})}
\end{equation}

The pulls are centered on 0 and have $\sigma$ close to 1, as expected.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{images/pulls_mc.pdf}
\caption{Pulls of the $\epsilon_{s}$ and $\epsilon_{b}$ parameters in 5000 toy MC.\label{fig:pullstp}}
\end{figure}
An example fit for one of the toys is shown in  Fig.~\ref{fig:toy_tp}
\begin{figure}[b]
\centering
\includegraphics[width=0.8\textwidth]{images/mc_pt_probe_toy.pdf}
\caption{Fit of a toy MC sample.\label{fig:toy_tp}}
\end{figure}

Before running the fit on data we have tried to validate the shapes used in the fit with data. To do so, we have made a much more pure $t\bar{t}$ selection, by requiring exactly two jets with \jpb score higher than 1.5 and no additional b-tagged jets, even if they have $\pt$ smaller than 30 \GeV. On this purer sample we have compared data against the shape used to fit the true b-jets in the \tpp{} distribution. The result is shown in Fig.~\ref{fig:purett} and shows good agreement.
\begin{figure}[t]
\centering
\includegraphics[width=0.6\textwidth]{images/passprobe_data_mc.pdf}
\caption{Shape comparison for the \probe{} $\pt$ spectrum in data and in MC in a very pure $t\bar{t}$ sample.\label{fig:purett}}
\end{figure}

We have finally performed the fit on data, as shown in Fig.~\ref{fig:data_tp}, which results in in the following efficiencies:
\begin{equation}
\epsilon_{s}^{Data}=0.769\pm0.022
\end{equation}
\begin{equation}
\epsilon_{b}^{Data}=0.121\pm0.054
\end{equation}

\begin{figure}[b]
\centering
\includegraphics[width=0.8\textwidth]{images/data_ptprobe.pdf}
\caption{Simultaneous fit of the \tpp{} and \tfp{} pairs in data.\label{fig:data_tp}}
\end{figure}
Further checks on the Tag\&Probe efficiencies are shown in Appendix~\ref{app:tpfractw}, which concern the uncertainty related to the not perfect knowledge of the $tW/t\bar{t}$ ratio in the MC.


\subsubsection{Data driven estimation \label{sec:DD}}
In addition to the b-tagging efficiency, the other ingredient to estimate the $t\bar{t}$ background is the process cross section. The idea is to measure the cross section in a $t\bar{t}$ enriched control region, that we call CtrlDD. CtrlDD is defined according to the lepton preselection cuts defined in Sec.~\ref{subsec:EventSelection}, and requiring in addition at least one jet with \jpb score higher than 1.4.

From the simulation we derive the factor $\alpha$ that connects CrtlDD to the signal region, from the ratio of $t\bar{t}$ events in the two regions.
\begin{equation}
\alpha=\frac{N_{t\bar{t}~MC}^{SIG}}{N_{t\bar{t}~MC}^{CtrlDD}}.
\end{equation}
We then count events CtrlDD in data, we subtract the expected number of events from non-$t\bar{t}$ backgrounds, and we obtain $N_{t\bar{t}~Data}^{CtrlDD}$. We finally obtain the number of expected $t\bar{t}$ events in the signal region ($N_{t\bar{t}~Data}^{SIG}$) as:
\begin{equation}
N_{t\bar{t}~Data}^{SIG} = \alpha{}N_{t\bar{t}~Data}^{CtrlDD}.
\end{equation}

In evaluating $\alpha$ and its error we made use of the b-tagging efficiencies determined in Sec.~\ref{sec:TagAndProbe}. 
%Since the efficiency and mistag rate that we have measured on data are close to the one in the MC we have decided assume a scale factor of 1 for both b-tagging efficiency and mis-tag rate, with an error that covers all of the difference between data and MC and the statistical uncertainty of the Tag\&Probe fit. In other other 
For each event we derive an efficiency scale factor and a mistag rate scale factor, depending on whether the event is in the signal or CtrlDD regions.
\begin{equation}
\label{eq:sfsig}
SF_{SIG} = \left(\frac{1-\epsilon_{s}^{Data}}{1-\epsilon_{s}^{MC}}\right)^{min(2, n_{b-jets})} \left(\frac{1-\epsilon_{b}^{Data}}{1-\epsilon_{b}^{MC}}\right)^{n_{non-b-jets}} 
\end{equation}

\begin{equation}
\label{eq:sfbkg}
SF_{CtrlDD} = \left(\frac{\epsilon_{s}^{Data}}{\epsilon_{s}^{MC}}\right)^{(jet1 == b-jet)} \left(\frac{\epsilon_{b}^{Data}}{\epsilon_{b}^{MC}}\right)^{(jet1 == non-b-jets)} 
\end{equation}
where $n_{b-jets})$ is the number of true b-jets in the event and $n_{non-b-jets}$ is the number of non-b-jets in the event. The writing $jet1 == b-jet$ ($jet1 == non-b-jets$) is a boolean flag that is true when the leading jet, the one used for the CtrlDD selection, is (not) a true b-jet.

Since the efficiency and mistag rate that we have measured on data are close to the one in the MC we have decided to assume a scale factor of 1 for both b-tagging efficiency and mis-tag rate. This means that the central values of the scale factors defined in Eq.~\ref{eq:sfsig} and Eq.~\ref{eq:sfbkg} is 1, but these numbers have an error that is derived assuming an uncertainty on $\epsilon_{s}^{Data}$ and $\epsilon_{b}^{Data}$ that covers both the statistical error from the fit of the two quantities and the difference with respect to the MC.
This results in an up variation and a down variation of the scale factors in the signal region and CtrlDD regions, that is used to derive an error on $\alpha$.

We have decided to make a data driven estimation of the $t\bar{t}$ background with the method described above in each of the $\pth$ bins independently. The reason why we have chosen to make this estimation in $\pth$ bins, rather than inclusively is explained in Fig.~\ref{fig:ttpth}. In this plot the $t\bar{t}$ background is normalized to the cross section measured by CMS. The binning is the same chosen for the analysis. As shown in the ratio plot, an overall normalization factor would not be able to accommodate for the variations of the Data/MC ratio from bin to bin.
\begin{figure}[b]
\centering
\includegraphics[width=0.6\textwidth]{images/ttpth.pdf}
\caption{$\pth$ variable in the CtrlDD control region.\label{fig:ttpth}}
\end{figure}

The $\alpha$ factors for each bin and the number of events in signal, CtrlDD region in MC as well as in data are listed in Tab.~\ref{tab:ttdd}.
%\centering
%\begin{tabular}{c c c c c c}
%\hline
%$\pth$ bin & $N_{t\bar{t}~Data}^{CtrlDD}$ & $N_{t\bar{t}~MC}^{CtrlDD}$ & $N_{t\bar{t}~MC}^{SIG}$ & $\alpha$ & $\Delta\alpha$ \\
%\hline
%1 & 406.73 & 358.78 & 117.83 & 0.328 & 0.075 \\ 

%2 & 2929.25 & 2703.44 & 859.08 & 0.318 & 0.071 \\ 

%3 & 5723.95 & 5465.37 & 1567.86 & 0.287 & 0.065 \\ 

%4 & 3863.39 & 3774.66 & 799.41 & 0.212 & 0.052 \\ 

%5 & 1533.61 & 1589.53 & 292.06 & 0.184 & 0.055 \\ 

%6 & 703.52 & 825.11 & 214.33 & 0.256 & 0.140 \\ 
%\hline

\begin{table}
\centering
\begin{tabular}{c c c c c c}

\hline\hline

$p_T^H$ bin & $N_{CTRL}^{DATA}$ & $N_{CTRL}^{TOP}$ &  $N_{SIG}^{TOP}$ &
$\alpha$ & $\Delta\alpha$ \\ 

\hline

1 & 406.71 & 358.78 & 117.83 & 0.328 & 0.075 \\ 

2 & 2930.14 & 2703.44 & 859.08 & 0.318 & 0.071 \\ 

3 & 5481.02 & 5207.48 & 1506.05 & 0.289 & 0.065 \\ 

4 & 4126.35 & 4032.56 & 861.22 & 0.214 & 0.052 \\ 

5 & 1612.64 & 1654.27 & 304.69 & 0.184 & 0.055 \\ 

6 & 647.50 & 760.37 & 201.70 & 0.265 & 0.147 \\ 

\hline

\end{tabular}
\caption{Table of data driven scale factors.\label{tab:ttdd}}
\end{table}
A comparison of the $\mll$ distribution in the six $\pth$ bins used in the analysis in CtrlDD after the data driven correction is shown in Fig.~\ref{fig:mllCtrlDD}
\begin{figure}[htb]
\centering
\subfigure[$\pth<15\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin0CtrlDD.pdf}}
\subfigure[$15\GeV<\pth<45\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin1CtrlDD.pdf}}

\subfigure[$45\GeV<\pth<85\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin2CtrlDD.pdf}}
\subfigure[$85\GeV<\pth<125\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin3CtrlDD.pdf}}

\subfigure[$125\GeV<\pth<165\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin4CtrlDD.pdf}}
\subfigure[$\pth>165\GeV$]{\includegraphics[width=0.35\textwidth]{images/mllBin5CtrlDD.pdf}}
\caption{$\mll$ distributions in the CtrlDD region for the different $\pth$ bins.\label{fig:mllCtrlDD}}
\end{figure}

























\clearpage
\subsection{\WW background \label{sec:WWBackground}}

For what the WW background shape is concerned the prediction from the Monte-Carlo simulation has been used.
This background is divided into six different parts, corresponding to the six bins of \pth considered. In each bin the normalization of the WW background is left free to float and is thus adjusted to match the data by the fit. In this way we minimize an effect that has been observed also in \cite{CMS_AN_2014_056}, that is a difference in shape between the $p_\mathrm{T}^\mathrm{WW}$ theory prediction and the distribution provided by the MC simulation, in our case by \textsc{Madgraph}.\\
In figure \ref{fig:ww_wwnlo} a comparison is shown between the $p_\mathrm{T}^\mathrm{WW}$ spectra of two different qqWW samples: the blue line corresponds to the WW \textsc{Madgraph} samples that we use in this analysis and the red line refers to the same sample in which a reweighting has been applied in order to match the theoretical prediction at NLO+NNLL precision. 
\begin{figure}[b]
\centering
\includegraphics[width=0.7\textwidth]{images/WWnlo/WW_WWnlo.pdf}
\caption{}\label{fig:ww_wwnlo}
\end{figure}
A shape discrepancy can be clearly observed and the effect becomes larger at high values of \pth.\\
In order to assess if these discrepancy has a not negligible effect on the shapes of the variables that we use for the fit, \mll and \mt, we checked these distributions in every \pth bin, comparing several samples. In particular we compared the \textsc{Madgraph} sample used for the nominal shape, the \textsc{Madgraph} sample with NLO+NNLL  reweighting, a \textsc{Powheg} NLO sample and an \textsc{aMC@NLO} sample.
The results of this comparison are shown in figures \ref{fig:ww_mll} and \ref{fig:ww_mth}. The discrepancy in shape among the different models is within the statistical accuracy of the MC samples. 

\begin{figure}[htb]
\centering
\subfigure[\mll bin 1]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin1.pdf}}
\subfigure[\mll bin 2]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin2.pdf}}\\
\subfigure[\mll bin 3]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin3.pdf}}
\subfigure[\mll bin 4]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin4.pdf}}\\
\subfigure[\mll bin 5]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin5.pdf}}
\subfigure[\mll bin 6]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mllBin6.pdf}}\\
\caption{Comparison between the default WW background sample and other theoretical models for the \mll distributions in every \pth bin.\label{fig:ww_mll}}
\end{figure}

\begin{figure}[htb]
\centering
\subfigure[\mt bin 1]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin1.pdf}}
\subfigure[\mt bin 2]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin2.pdf}}\\
\subfigure[\mt bin 3]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin3.pdf}}
\subfigure[\mt bin 4]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin4.pdf}}\\
\subfigure[\mt bin 5]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin5.pdf}}
\subfigure[\mt bin 6]{\includegraphics[width=0.45\textwidth]{images/WWnlo/mthBin6.pdf}}\\
\caption{Comparison between the default WW background sample and other theoretical models for the \mt distributions in every \pth bin.\label{fig:ww_mth}}
\end{figure}














































\subsection{Other backgrounds\label{sec:OtherBackgrounds}}

	%------------------------------------------------------------------------------------
	\subsubsection{W+jets background\label{sec:wjetsbkg}}	
Backgrounds containing one or two fake leptons are estimated from events
selected with relaxed lepton quality criteria, using the efficiencies for
real and fake leptons to pass the tight lepton quality cuts of the analysis. 

A data-driven approach, described in detail in~\cite{AN-2010-261} and~\cite{AN-2010-397}, is pursued 
to estimate this background. A set of loosely selected lepton-like objects, referred to as the 
'fakeable object' or ``denominator'' from here on, is defined in a sample of events 
dominated by dijet production. The denominator object definition used in the full 2012
data is described in~\cite{AN-2012-378}.

To measure the fake rate we count how many fakeable objects pass the full lepton selection 
of the analysis, parametrized as a function of the phase space of the fakeable lepton, therefore 
it is extracted in bins of $\eta$ and p$_T$.


The ratio of the fully identified lepton, referred as ``numerator'', to the 
fakeable objects is taken as the probability for a fakeable object to fake a lepton:

\begin{equation} 
{\mbox Fake\ Rate } = \frac{\# of \ fully \ reconstructed \ leptons}{\# of \ fakeable \ objects} 
\end{equation}

It is then used to extrapolate from the loose leptons sample to a sample of leptons satisfying the  
full selection. 

The details of the method implementation can be found in~\cite{AN-2013-022}.
% and only final results are quoted
%here. The resultant background yield estimates at the \WW selection level are given in Table~\ref{tab:WjetsBackground}.
The systematic uncertainty is evaluated by varying the jet thresholds in the di-jet control sample, and by
performing a closure test in the same-sign data sample (see~\cite{AN-2013-022}). In both cases it is about 36\%.

	%-------------------------------------------------------------------------------
	\subsubsection{Drell-Yan to \texorpdfstring{$\tau\tau$}{tau tau} background\label{sec:DYtautaubkg}}


The low \MET threshold in e$\mu$ final state
requires the consideration of the contribution from 
\dytt\, that is infact estimated from data.
This is accomplished by using 
\dymm events and replacing muons with a simulated
$\tau\to l\nu_\tau\bar{\nu_e}$ decay \cite{AN-2011-020}.\\
After replacing muons from \dymm decays with simulated $\tau$ decays,
the set of pseudo \dytt events undergoes the reconstruction step.
 
Good agreement in kinematic distributions for this sample
and a Monte Carlo based \dytt sample is found.
The global normalization of pseudo \dytt events is 
checked in the low \mt spectrum where a rather pure
\dytt sample is expected.


	%-------------------------------------------------------------------------------
	\subsubsection{ZZ, WZ and W\texorpdfstring{$\gamma$}{gamma} backgrounds\label{sec:otherbkg}}

The WZ and ZZ backgrounds are partially estimated from data when the two
selected leptons come from the same Z boson. If the leptons come from different
bosons the contribution is expected to be small. The WZ component is largely
rejected by requiring only two high \pt isolated leptons in the event. 
%The missing energy requirement makes the ZZ~$\to 4\ell$ component almost negligible.
%As the extra lepton veto and the \met cuts do not remove the ZZ~$\to 2\ell 2\nu$
%decays, a non-negligible fraction of these events survives the selection for $ee$ and $\mu\mu$ channels only. 

The W+$\gamma^{(*)}$ background, where the photon decays to an electron-positron pair,
is expected to be very small, thanks to the stringent photon conversion
requirements.
 Since the WZ simulated sample has a generation level cut on the
di-lepton invariant mass ($m_{\ell\ell} >$ 12~\GeV) and the cross-section raises
quickly with the lowering of this threshold, a dedicated \textsc{Madgraph} sample has
been produced with lower momentum cuts on two of the three leptons
($\pt > 5$~\GeV) and no cut on the third one. The surviving contribution
estimated with this sample is still very small, and since the uncertainty on the
cross-section for the covered phase space is large, a conservative 100\%
uncertainty has been given to it. 
A $k$-factor for W+$\gamma^{*}$ of $1.5\pm0.5$ based on a dedicated measurement of 
tri-lepton decays, W+$\gamma^{*} \to e\mu\mu$ and W+$\gamma^{*} \to \mu\mu\mu$,
is applied~\cite{WGammaStarStudy}. 
The contribution of W+$\gamma^{(*)}$ is also
constrained by a closure test with same sign leptons on data, which reveals a
good compatibility of the data with the expected background.

